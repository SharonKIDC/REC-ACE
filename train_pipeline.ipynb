{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3795bd4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7144af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm, tqdm_note\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "from data_utils.dataset import prepare_data\n",
    "from data_utils.utils import read_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d452f17",
   "metadata": {},
   "source": [
    "## Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f64c8454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x105f961f0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Set the random seed for Python\n",
    "random.seed(SEED)\n",
    "\n",
    "# Set the random seed for numpy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set the random seed for pandas\n",
    "# pandas gets its random seed from numpy, so using numpy's seed will affect pandas\n",
    "\n",
    "# Set the random seed for NLTK\n",
    "# NLTK gets its random seed from the Python random number generator (using random.seed())\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374660e0",
   "metadata": {},
   "source": [
    "# Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f526e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dict = {\n",
    "    # Default\n",
    "    'Default Train Clean': 'data/default/train_clean.json',\n",
    "    'Default Train Other': 'data/default/train_other.json',\n",
    "    'Default Dev Clean': 'data/default/dev_clean.json',\n",
    "    'Default Dev Other': 'data/default/dev_other.json',\n",
    "    'Default Test Clean': 'data/default/test_clean.json',\n",
    "    'Default Test Other': 'data/default/test_other.json',\n",
    "    # Video\n",
    "    'Video Train Clean': 'data/video/train_clean.json',\n",
    "    'Video Train Other': 'data/video/train_other.json',\n",
    "    'Video Dev Clean': 'data/video/dev_clean.json',\n",
    "    'Video Dev Other': 'data/video/dev_other.json',\n",
    "    'Video Test Clean': 'data/video/test_clean.json',\n",
    "    'Video Test Other': 'data/video/test_other.json', \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882a9f3",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e0d69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8b502",
   "metadata": {},
   "source": [
    "## Load essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9919c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 't5-small'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb55b6b",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dea34263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4caee7",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d762cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c4174",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d885b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = read_json(json_path=datasets_dict['Default Train Clean'])\n",
    "dev_set = read_json(json_path=datasets_dict['Default Dev Clean'])\n",
    "test_set = read_json(json_path=datasets_dict['Default Test Clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac45950",
   "metadata": {},
   "source": [
    "## Prepare as DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c689bdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 103895/103895 [00:09<00:00, 10425.14it/s]\n",
      "100%|██████████████████████████████████████████| 2697/2697 [00:00<00:00, 15090.89it/s]\n",
      "100%|██████████████████████████████████████████| 2615/2615 [00:00<00:00, 15048.03it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "train_loader = prepare_data(data=train_set, tokenizer=tokenizer, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = prepare_data(data=dev_set, tokenizer=tokenizer, batch_size=batch_size, shuffle=False)\n",
    "test_loader = prepare_data(data=test_set , tokenizer=tokenizer, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b63e8a",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ab6c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15f674c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04fd0ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, n_epochs, train_data, dev_data, optimizer, criterion):\n",
    "    \"\"\" Training loop for the model\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): Model to train\n",
    "            n_epochs (int): Number of epochs to train\n",
    "            train_data (DataLoader): DataLoader with train data\n",
    "            dev_data (DataLoader): DataLoader with dev data\n",
    "            optimizer (torch.optim): Optimizer for the model\n",
    "            criterion (torch.nn): Loss function\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary with train and dev losses and accuracies\n",
    "    \"\"\"\n",
    "\n",
    "    # metrics placeholder for recording training stats\n",
    "    metrics = {\n",
    "        'loss': {\n",
    "            'train': [],\n",
    "            'dev':   []\n",
    "        },\n",
    "        'acc': {\n",
    "            'train': [],\n",
    "            'dev':   []\n",
    "        }\n",
    "    }\n",
    "    pbar = tqdm(range(n_epochs), position=0, desc=f\"\\tEpoch: {1}/{n_epochs}\")\n",
    "    for epoch in pbar:\n",
    "\n",
    "        train_losses, train_acc = [], []\n",
    "        dev_losses, dev_acc = [], []\n",
    "\n",
    "        ### TRAIN\n",
    "        model.train()\n",
    "\n",
    "        # Iterating over batches in train data\n",
    "        pbar_train = tqdm_notebook(train_data, position=1)\n",
    "        for i_batch, batch in enumerate(pbar_train):\n",
    "            pbar_train.set_description(f\"Training on batch: {i_batch+1}/{len(train_data)}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            X = batch['sentences'].to(DEVICE)\n",
    "            y = batch['labels'].to(DEVICE)\n",
    "\n",
    "            loss = model(input_ids=X, labels=y).loss\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        ### Evaluate DEV set\n",
    "        model.eval()\n",
    "\n",
    "        # No need for gradients when evaluating\n",
    "        with torch.no_grad():\n",
    "            pbar_dev = tqdm_notebook(dev_data, position=2)\n",
    "            for i_batch, batch in enumerate(pbar_dev):\n",
    "                pbar_dev.set_description(f\"DEV Iteration: {i_batch+1}/{len(dev_data)}\")\n",
    "\n",
    "\n",
    "                X = batch['sentences'].to(DEVICE)\n",
    "                y = batch['labels'].to(DEVICE)\n",
    "\n",
    "                loss = model(input_ids=X, labels=y).loss\n",
    "       \n",
    "                # Calculate DEV loss\n",
    "                loss = criterion(preds, y_hot)\n",
    "                dev_losses.append(loss.item())\n",
    "\n",
    "\n",
    "        # Collect epoch's avg scores\n",
    "        metrics['loss']['train'].append(np.mean(train_losses))\n",
    "        metrics['loss']['dev'].append(np.mean(dev_losses))\n",
    "\n",
    "        pbar.set_description(f\"\\tEpoch: {epoch+1}/{n_epochs}, \\t Train Loss AVG: {metrics['loss']['train'][-1]:.04}, Dev Loss AVG: {metrics['loss']['dev'][-1]:.04}\")\n",
    "\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8fcc5a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tEpoch: 1/20:   0%|                                            | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tqdm_notebook' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 2\u001b[0m model, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdev_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, n_epochs, train_data, dev_data, optimizer, criterion)\u001b[0m\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Iterating over batches in train data\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m pbar_train \u001b[38;5;241m=\u001b[39m \u001b[43mtqdm_notebook\u001b[49m(train_data, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_batch, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar_train):\n\u001b[1;32m     39\u001b[0m     pbar_train\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_batch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm_notebook' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model, metrics = training(model=model,\n",
    "                          n_epochs=20,\n",
    "                          train_data=train_loader,\n",
    "                          dev_data=dev_loader,\n",
    "                          optimizer=optimizer,\n",
    "                          criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b202bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
